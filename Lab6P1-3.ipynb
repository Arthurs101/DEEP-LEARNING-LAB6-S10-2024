{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26a8d148",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef3befadb7778a3e2158a5215f5bde45",
     "grade": false,
     "grade_id": "cell-d22b0a1a95048dd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Laboratorio 6 Parte 1\n",
    "\n",
    "En este laboratorio, estaremos repasando los conceptos de Generative Adversarial Networks En la primera parte nos acercaremos a esta arquitectura a través de buscar aproximar una función. Esta vez ya no usaremos versiones deprecadas de la librería de PyTorch, por ende, creen un nuevo virtual env con las librerías más recientes que puedan por favor.\n",
    "\n",
    "Al igual que en laboratorios anteriores, para este laboratorio estaremos usando una herramienta para Jupyter Notebooks que facilitará la calificación, no solo asegurándo que ustedes tengan una nota pronto sino también mostrandoles su nota final al terminar el laboratorio.\n",
    "\n",
    "De nuevo me discupo si algo no sale bien, seguiremos mejorando conforme vayamos iterando. Siempre pido su comprensión y colaboración si algo no funciona como debería. \n",
    "\n",
    "Al igual que en el laboratorio pasado, estaremos usando la librería de Dr John Williamson et al de la University of Glasgow, además de ciertas piezas de código de Dr Bjorn Jensen de su curso de Introduction to Data Science and System de la University of Glasgow para la visualización de sus calificaciones. \n",
    "\n",
    "**NOTA:** Ahora tambien hay una tercera dependecia que se necesita instalar. Ver la celda de abajo por favor\n",
    "\n",
    "<script type=\"text/javascript\" src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1af490f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:21.225179Z",
     "start_time": "2023-08-22T01:05:21.206664Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15d9e36eb3d6eda1ea8b6ad946164088",
     "grade": false,
     "grade_id": "cell-e74d9bdf886d7f55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "DEPRECATION: Loading egg at c:\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/johnhw/jhwutils/zipball/master\n",
      "  Downloading https://github.com/johnhw/jhwutils/zipball/master\n",
      "     - 0 bytes ? 0:00:00\n",
      "     | 118.3 kB 607.5 kB/s 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: jhwutils\n",
      "  Building wheel for jhwutils (setup.py): started\n",
      "  Building wheel for jhwutils (setup.py): finished with status 'done'\n",
      "  Created wheel for jhwutils: filename=jhwutils-1.2-py3-none-any.whl size=41055 sha256=8a8ef1feb5496d480072d7e3a87bff7db39ab9e5f40d9d33cd7cf469f0ca3827\n",
      "  Stored in directory: C:\\Users\\inmar\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-k7e0d8ik\\wheels\\a8\\e7\\e3\\9542f8e4159ba644c6acd9f78babbe8489bb72667fb02ac54d\n",
      "Successfully built jhwutils\n",
      "Installing collected packages: jhwutils\n",
      "  Attempting uninstall: jhwutils\n",
      "    Found existing installation: jhwutils 1.2\n",
      "    Uninstalling jhwutils-1.2:\n",
      "      Successfully uninstalled jhwutils-1.2\n",
      "Successfully installed jhwutils-1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "DEPRECATION: Loading egg at c:\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\python311\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\python311\\lib\\site-packages (from scikit-image) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\python311\\lib\\site-packages (from scikit-image) (1.12.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\python311\\lib\\site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\python311\\lib\\site-packages (from scikit-image) (10.0.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\python311\\lib\\site-packages (from scikit-image) (2.34.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\python311\\lib\\site-packages (from scikit-image) (2024.7.24)\n",
      "Requirement already satisfied: packaging>=21 in c:\\python311\\lib\\site-packages (from scikit-image) (23.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\python311\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Collecting https://github.com/AlbertS789/lautils/zipball/master\n",
      "  Downloading https://github.com/AlbertS789/lautils/zipball/master\n",
      "     - 0 bytes ? 0:00:00\n",
      "     - 4.2 kB ? 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: lautils\n",
      "  Building wheel for lautils (setup.py): started\n",
      "  Building wheel for lautils (setup.py): finished with status 'done'\n",
      "  Created wheel for lautils: filename=lautils-1.0-py3-none-any.whl size=2833 sha256=ca7bc6ce264b0a14f710be3e42c624a09306cd88e0c45c9a0b22285a9917869e\n",
      "  Stored in directory: C:\\Users\\inmar\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-kkc9lq2b\\wheels\\1a\\50\\ba\\b3ceb937949f5894a896b68af5b5fdb598e50244141063e4db\n",
      "Successfully built lautils\n",
      "Installing collected packages: lautils\n",
      "  Attempting uninstall: lautils\n",
      "    Found existing installation: lautils 1.0\n",
      "    Uninstalling lautils-1.0:\n",
      "      Successfully uninstalled lautils-1.0\n",
      "Successfully installed lautils-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "DEPRECATION: Loading egg at c:\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Una vez instalada la librería por favor, recuerden volverla a comentar.\n",
    "# !pip install -U --force-reinstall --no-cache https://github.com/johnhw/jhwutils/zipball/master\n",
    "# !pip install scikit-image\n",
    "# !pip install -U --force-reinstall --no-cache https://github.com/AlbertS789/lautils/zipball/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de89670f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:22.570235Z",
     "start_time": "2023-08-22T01:05:21.228169Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe2113ec92b93ee2a5cf1a59377a957f",
     "grade": false,
     "grade_id": "cell-6ac4f1ed77427074",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "#from IPython import display\n",
    "#from base64 import b64decode\n",
    "\n",
    "\n",
    "# Other imports\n",
    "from unittest.mock import patch\n",
    "from uuid import getnode as get_mac\n",
    "\n",
    "from jhwutils.checkarr import array_hash, check_hash, check_scalar, check_string, array_hash, _check_scalar\n",
    "import jhwutils.image_audio as ia\n",
    "import jhwutils.tick as tick\n",
    "from lautils.gradeutils import new_representation, hex_to_float, compare_numbers, compare_lists_by_percentage, calculate_coincidences_percentage\n",
    "\n",
    "###\n",
    "tick.reset_marks()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12718475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:22.585673Z",
     "start_time": "2023-08-22T01:05:22.571202Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89fd2e761a928fe72d6940424922ea1b",
     "grade": true,
     "grade_id": "cell-390a3083c0cdea85",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Celda escondida para utlidades necesarias, por favor NO edite esta celda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44132f6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2da785101e1cc39a12741a7eb0f90df7",
     "grade": false,
     "grade_id": "cell-ce2f24821ed0978f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "###### Información del estudiante en dos variables\n",
    "\n",
    "* carne_1 : un string con su carne (e.g. \"12281\"), debe ser de al menos 5 caracteres.\n",
    "* firma_mecanografiada_1: un string con su nombre (e.g. \"Albero Suriano\") que se usará para la declaracion que este trabajo es propio (es decir, no hay plagio)\n",
    "* carne_2 : un string con su carne (e.g. \"12281\"), debe ser de al menos 5 caracteres.\n",
    "* firma_mecanografiada_2: un string con su nombre (e.g. \"Albero Suriano\") que se usará para la declaracion que este trabajo es propio (es decir, no hay plagio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf0be2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:22.601669Z",
     "start_time": "2023-08-22T01:05:22.588185Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1ce0139d077928e2dc046ab0e340177",
     "grade": false,
     "grade_id": "cell-359a6f8b5bf8c2b3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "carne_1 = \"21527\"\n",
    "firma_mecanografiada_1 =  \"Arturo Argueta\"\n",
    "carne_2 = \"20172\"\n",
    "firma_mecanografiada_2 =  \"Diego Medinilla\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f458a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:22.617154Z",
     "start_time": "2023-08-22T01:05:22.604661Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02cc459a081d0939998dc1d0de1ff8d1",
     "grade": true,
     "grade_id": "cell-0f320f6e0f897f6c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div class=\"alert alert-box alert-success\">\n",
       "        <h1> <!--{id:\"CORRECTMARK\", marks:\"0\"}--> \n",
       "         ✓ [0 marks] \n",
       "         </h1> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div class=\"alert alert-box alert-success\">\n",
       "        <h1> <!--{id:\"CORRECTMARK\", marks:\"0\"}--> \n",
       "         ✓ [0 marks] \n",
       "         </h1> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deberia poder ver dos checkmarks verdes [0 marks], que indican que su información básica está OK \n",
    "\n",
    "with tick.marks(0): \n",
    "    assert(len(carne_1)>=5 and len(carne_2)>=5)\n",
    "\n",
    "with tick.marks(0):  \n",
    "    assert(len(firma_mecanografiada_1)>0 and len(firma_mecanografiada_2)>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab4d82e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a242aacebd30d8687e18c5d525e7a3ee",
     "grade": false,
     "grade_id": "cell-c37faff63689fa77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Introducción\n",
    "\n",
    "**Créditos:** Esta parte de este laboratorio está tomado y basado en uno de los blogs de Renato Candido, así como las imagenes presentadas en este laboratorio a menos que se indique lo contrario.\n",
    "\n",
    "Los Generative Adversarial Networks representan sistemas de aprendizaje automático capaces de aprender a imitar una distribución específica de datos. Estos fueron propuestos por primera vez en un artículo de NeurIPS en 2014 por Ian Goodfellow, un experto en el campo del aprendizaje profundo, y sus colegas.\n",
    "\n",
    "Las GAN consisten en dos redes neuronales, una de las cuales se entrena para generar datos, mientras que la otra se entrena para discernir entre datos falsos y auténticos (de ahí proviene la naturaleza \"adversarial\" del modelo). Aunque la noción de una estructura destinada a la generación de datos no es novedosa, en lo que respecta a la creación de imágenes y videos, las GAN han arrojado resultados sorprendentes,\n",
    "\n",
    "Architecturas que producen datos, como las GAN, se clasifican como modelos generativos en contraste con los modelos discriminatorios, que son más ampliamente estudiados. Antes de adentrarnos en las GAN, exploraremos las diferencias entre estos dos tipos de modelos.\n",
    "\n",
    "La mayoría de las aplicaciones con las que te hemos trabajado hasta ahora han sido implementaciones usando modelos discriminatorios. Por otro lado, las redes generativas adversarias pertenecen a una categoría diferente de modelos conocidos como modelos generativos.\n",
    "\n",
    "Los modelos discriminatorios son aquellos que se utilizan para la mayoría de los problemas de clasificación o regresión supervisada. Como ejemplo de un problema de clasificación, supongamos que deseamos entrenar un modelo para clasificar imágenes de dígitos escritos a mano del 0 al 9 (un ejemplo bastante común). Para esto, podríamos usar un conjunto de datos etiquetado que contenga imágenes de dígitos escritos a mano y sus etiquetas asociadas que indican qué dígito representa cada imagen.\n",
    "\n",
    "Durante el proceso de entrenamiento, utilizaríamos un algoritmo para ajustar los parámetros del modelo. El objetivo sería minimizar una función de pérdida para que el modelo aprenda la **distribución de probabilidad** de la salida dada la entrada. Después de la fase de entrenamiento, podríamos utilizar el modelo para clasificar una nueva imagen de un dígito escrito a mano estimando el dígito más probable al que corresponde la entrada según lo aprendindo durante la fase de entrenamiento.\n",
    "\n",
    "![](https://files.realpython.com/media/fig_discriminative.9c22a1cd877d.png)\n",
    "\n",
    "Los modelos discriminativos para problemas de clasificación pueden ser visualizados como bloques que utilizan los datos de entrenamiento para aprender los límites entre las clases. Luego, utilizan estos límites para discriminar una entrada y predecir su clase. En términos matemáticos, los modelos discriminativos aprenden la probabilidad condicional P(y|x) de la salida \"y\" dada la entrada \"x\".\n",
    "\n",
    "Además de las redes neuronales, otras estructuras pueden ser utilizadas como modelos discriminativos, como modelos de regresión logística y máquinas de soporte vectorial (SVM).\n",
    "\n",
    "Por otro lado, los modelos generativos como las GANs se entrenan para describir cómo se genera un conjunto de datos en términos de un modelo probabilístico. Al muestrear de un modelo generativo, podemos generar nuevos datos. Mientras que los modelos discriminativos se utilizan para el aprendizaje supervisado, los modelos generativos a menudo se emplean con conjuntos de datos no etiquetados y pueden considerarse como una forma de aprendizaje no supervisado.\n",
    "\n",
    "Utilizando el conjunto de datos de dígitos escritos a mano, podríamos entrenar un modelo generativo para generar nuevos dígitos. Durante la fase de entrenamiento, utilizaríamos algún algoritmo para ajustar los parámetros del modelo y minimizar una función de pérdida para aprender la distribución de probabilidad del conjunto de entrenamiento. Luego, con el modelo entrenado, podríamos generar nuevas muestras.\n",
    "\n",
    "![](https://files.realpython.com/media/fig_generative.5f01c08f5208.png)\n",
    "\n",
    "\n",
    "Para producir nuevas muestras, los modelos generativos suelen incorporar un elemento **estocástico** o aleatorio que influye en las muestras generadas por el modelo. Las muestras aleatorias utilizadas para impulsar el generador se obtienen de un **espacio latente** en el que los vectores representan una especie de forma comprimida de las muestras generadas.\n",
    "\n",
    "A diferencia de los modelos discriminativos, los modelos generativos aprenden la probabilidad P(x) de los datos de entrada \"x\", y al tener la distribución de los datos de entrada, pueden generar nuevas instancias de datos.\n",
    "\n",
    "Vale la pena mencionar que los modelos generativos también pueden ser utilizados con conjuntos de datos etiquetados. Cuando lo son, se entrenan para aprender la probabilidad P(x|y) de la entrada \"x\" dado el resultado \"y\". También pueden ser utilizados para tareas de clasificación, pero en general, los modelos discriminativos tienen un mejor rendimiento en lo que respecta a la clasificación.\n",
    "\n",
    "\n",
    "### Sobre la Arquitectura\n",
    "\n",
    "Las redes Generativas Adversarias están compuestas por una estructura global que consta de dos redes neuronales, una llamada generador y otra llamada discriminador.\n",
    "\n",
    "El papel del generador es estimar la distribución de probabilidad de las muestras reales para proporcionar muestras generadas que se asemejen a datos reales. El discriminador, a su vez, se entrena para estimar la probabilidad de que una muestra dada provenga de los datos reales en lugar de ser proporcionada por el generador.\n",
    "\n",
    "Estas estructuras se llaman redes generativas adversarias porque el generador y el discriminador se entrenan para competir entre sí: el generador intenta mejorar engañando al discriminador, mientras que el discriminador intenta mejorar identificando muestras generadas.\n",
    "\n",
    "Para comprender cómo funciona el entrenamiento de las GAN, vamos a considerar un ejemplo sencillo con un conjunto de datos compuesto por muestras bidimensionales (x₁, x₂), donde x₁ está en el intervalo de 0 a 2π y x₂ = sin(x₁). Una función que se puede visualizar como la siguiente imagen:\n",
    "\n",
    "![](https://files.realpython.com/media/fig_x1x2.f8a39d8ff58a.png)\n",
    "\n",
    "Como se puede ver, este conjunto de datos consiste en puntos (x₁, x₂) ubicados sobre una curva senoidal, que tiene una distribución muy particular. La estructura general de una GAN para generar pares (x̃₁, x̃₂) que se asemejen a las muestras del conjunto de datos se muestra en la siguiente figura:\n",
    "\n",
    "![](https://files.realpython.com/media/fig_gan.4f0f744c7999.png)\n",
    "\n",
    "El generador G recibe datos aleatorios de un espacio latente, y su función es generar datos que se parezcan a las muestras reales. En este ejemplo, se tiene un espacio latente bidimensional, de manera que el generador recibe pares aleatorios (z₁, z₂) y debe transformarlos de manera que se asemejen a las muestras reales.\n",
    "\n",
    "La estructura de la red neuronal G puede ser arbitraria, lo que te permite utilizar redes neuronales como multi-layer perceptron (MLP), redes neuronales convolucionales (CNN) o cualquier otra estructura, **siempre que las dimensiones de la entrada y la salida coincidan con las dimensiones del espacio latente y los datos reales.**\n",
    "\n",
    "El discriminador D recibe muestras reales del conjunto de datos de entrenamiento o muestras generadas proporcionadas por G. Su función es estimar la probabilidad de que la entrada pertenezca al conjunto de datos reales. El entrenamiento se realiza de manera que D emita un 1 cuando se le proporciona una muestra real y un 0 cuando se le proporciona una muestra generada.\n",
    "\n",
    "Al igual que con G, se puede elegir una estructura de red neuronal arbitraria para D, siempre que respete las dimensiones necesarias de entrada y salida. En esta primera parte, la entrada es bidimensional. Para un discriminador binario, la salida puede ser un escalar que varía entre 0 y 1.\n",
    "\n",
    "El proceso de entrenamiento de GAN consiste en un juego minimax (¿les suena o recuerdan este concepto?) de dos jugadores en el que D se adapta para minimizar el error de discriminación entre muestras reales y generadas, y G se adapta para maximizar la probabilidad de que D cometa un error.\n",
    "\n",
    "Aunque el conjunto de datos que contiene los datos reales no está etiquetado, los procesos de entrenamiento para D y G se realizan de manera supervisada. En cada paso del entrenamiento, los parámetros de D y G se actualizan. De hecho, en la propuesta original de las GAN, los parámetros de D se actualizan k veces, mientras que los parámetros de G se actualizan solo una vez en cada paso de entrenamiento. Sin embargo, para simplificar el entrenamiento, se puede considerar k igual a 1.\n",
    "\n",
    "Para entrenar a D, en cada iteración se etiquetan algunas muestras reales tomadas de los datos de entrenamiento como 1 y algunas muestras generadas proporcionadas por G como 0. De esta manera, puedes utilizar un marco de entrenamiento supervisado convencional para actualizar los parámetros de D con el fin de minimizar una función de pérdida, como se muestra en el siguiente esquema:\n",
    "\n",
    "![](https://files.realpython.com/media/fig_train_discriminator.cd1a1e32764f.png)\n",
    "\n",
    "Para cada batch de datos de entrenamiento que contiene muestras reales y generadas, se actualizan los parámetros de D para minimizar una función de pérdida. Después de actualizar los parámetros de D, se entrena a G para producir mejores muestras generadas. La salida de G está conectada a D, cuyos parámetros se mantienen congelados, como se muestra aquí:\n",
    "\n",
    "![](https://files.realpython.com/media/fig_train_generator.7196c4f382ba.png)\n",
    "\n",
    "Se puede imaginar el sistema compuesto por G y D como un sistema de clasificación único que recibe muestras aleatorias como entrada y produce la clasificación, que en este caso puede interpretarse como una probabilidad.\n",
    "\n",
    "Cuando G hace un trabajo lo suficientemente bueno como para engañar a D, la probabilidad de salida debería estar cerca de 1. También se podría utilizar un framework de entrenamiento supervisado convencional aquí: el conjunto de datos para entrenar el sistema de clasificación compuesto por G y D sería proporcionado por muestras de entrada aleatorias, y la etiqueta asociada con cada muestra de entrada sería 1.\n",
    "\n",
    "Durante el entrenamiento, a medida que se actualizan los parámetros de D y G, se espera que las muestras generadas proporcionadas por G se parezcan más a los datos reales, y que D tenga más dificultades para distinguir entre datos reales y generados.\n",
    "\n",
    "Ahora sí, después de tan largo preambulo, empecemos a trabajar sobre nuestra primera GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af930d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:23.804126Z",
     "start_time": "2023-08-22T01:05:22.618151Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55a8192dbeafddfd102461188fc6fc31",
     "grade": false,
     "grade_id": "cell-342bf17cb8fdb5a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6032dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:23.819134Z",
     "start_time": "2023-08-22T01:05:23.805123Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5123929b3ebbd3953cd58f7c91e0c75",
     "grade": false,
     "grade_id": "cell-e4daee81985d03d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "seed_ = 2023\n",
    "random.seed(seed_)\n",
    "np.random.seed(seed_)\n",
    "torch.manual_seed(seed_)\n",
    "torch.cuda.manual_seed(seed_)\n",
    "#torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c4e689",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "786557f62875429b2fb5660b03889a0b",
     "grade": false,
     "grade_id": "cell-1fa8b883664e10ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Data de Entrenamiento\n",
    "\n",
    "Los datos de entrenamiento están compuestos por pares (x₁, x₂) de manera que x₂ consiste en el valor del seno de x₁, donde x₁ está en el intervalo de 0 a 2π.\n",
    "\n",
    "Aquí, se compone un conjunto de entrenamiento con 1024 pares (x₁, x₂). Luego, se inicializa train_data, un tensor con dimensiones de 1024 filas y 2 columnas, todos conteniendo ceros. Un tensor es un arreglo multidimensional similar a un arreglo NumPy.\n",
    "\n",
    "Después, se utiliza la primera columna de train_data para almacenar valores aleatorios en el intervalo de 0 a 2π. Luego, se calcula la segunda columna del tensor como el seno de la primera columna.\n",
    "\n",
    "Luego, se necesitará un tensor de etiquetas, que son necesarias para el loader de datos de PyTorch. Dado que las GAN hacen uso de técnicas de aprendizaje no supervisado, las etiquetas pueden ser cualquier cosa. Después de todo, no se utilizarán.\n",
    "\n",
    "Luego, se crea train_labels, un tensor lleno de ceros. Finalmente, se crea train_set como una lista de tuplas, donde cada fila de train_data y train_labels está representada en cada tupla como se espera para el cargador de datos de PyTorch.\n",
    "\n",
    "Más adelante, con train_set se crea el data loader.\n",
    "\n",
    "Despues, se crea un data loader llamado train_loader, que mezclará los datos de train_set y devolverá batches de 32 muestras que se utilizarán para entrenar las redes neuronales.\n",
    "\n",
    "Después de configurar los datos de entrenamiento, se necesita crear las redes neuronales para el discriminador y el generador que compondrán la GAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5e1c381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:23.834960Z",
     "start_time": "2023-08-22T01:05:23.821470Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a037bc9ddfc4fd9471599a75b5662d34",
     "grade": false,
     "grade_id": "cell-e4b84d4f789184fa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_data_length = 1024\n",
    "\n",
    "train_data = torch.zeros(train_data_length, 2)\n",
    "train_data[:, 0] = 2 * math.pi * torch.rand(train_data_length)\n",
    "train_data[:, 1] = torch.sin(train_data[:, 0])\n",
    "train_labels = torch.zeros(train_data_length)\n",
    "\n",
    "train_set = [(train_data[i], train_labels[i]) for i in range(train_data_length)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbdf6675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:23.850329Z",
     "start_time": "2023-08-22T01:05:23.836955Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ef4c1462ad7a3f86ea1a96203c5e13b",
     "grade": false,
     "grade_id": "cell-a274f1c593cb647b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb8f61f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "614ac65e587345fb17a1f42a6f95919e",
     "grade": false,
     "grade_id": "cell-3baf9107a13f6b23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Implementando el Discriminador\n",
    "\n",
    "En PyTorch, como bien hemos visto hasta ahora, los modelos de redes neuronales se representan mediante clases que heredan de nn.Module, por lo que se deberá definir una clase para crear el discriminador. \n",
    "\n",
    "El discriminador es un modelo con una entrada bidimensional y una salida unidimensional. Se recibirá una muestra de los datos reales o del generador y se proporcionará la probabilidad de que la muestra pertenezca a los datos de entrenamiento reales. \n",
    "\n",
    "Se utiliza .init() para construir el modelo. En primer lugar, es necesario llamar a super().init() para ejecutar .init() de nn.Module. El discriminador que se está utilizando es una red neuronal MLP definida de manera secuencial utilizando nn.Sequential(). Tiene las siguientes características:\n",
    "\n",
    "* La entrada es bidimensional y la primera capa oculta está compuesta por 256 neuronas con activación ReLU.\n",
    "\n",
    "* La segunda y tercera capas ocultas están compuestas por 128 y 64 neuronas, respectivamente, con activación ReLU.\n",
    "\n",
    "* La salida está compuesta por una única neurona con activación sigmoide para representar una probabilidad.\n",
    "\n",
    "* Después de la primera, segunda y tercera capas ocultas, se utiliza dropout para evitar el sobreajuste.\n",
    "\n",
    "Finalmente, se utiliza .forward() para describir cómo se calcula la salida del modelo. Aquí, \"x\" representa la entrada del modelo, que es un tensor bidimensional. En esta implementación, la salida se obtiene alimentando la entrada x al modelo que se ha definido sin ningún otro procesamiento.\n",
    "\n",
    "El discriminador representa una instancia de la red neuronal que se ha definido y está listo para ser entrenado. Sin embargo, antes de implementar el ciclo de entrenamiento, la GAN también necesita un generador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "478ddfa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:23.865336Z",
     "start_time": "2023-08-22T01:05:23.852325Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5ba304e71ece7d70910c50c1ccb0c78",
     "grade": false,
     "grade_id": "cell-520ed8d07dcaf1c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # Capa linea e entrada 2 y salida 256\n",
    "            # Activacion ReLU\n",
    "            # Dropout con probabilidad 30%\n",
    "            nn.Linear(2, 256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Dropout de 30%\n",
    "            # Lineal de entrada que haga match y salida 1\n",
    "            # Sigmoide\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b87778",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:23.881338Z",
     "start_time": "2023-08-22T01:05:23.866335Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d54b7237531498b39d119c908b85bf1",
     "grade": false,
     "grade_id": "cell-d231beb0bf3a97c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3075cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56d5850506bd62639c5f3c22a1b95773",
     "grade": false,
     "grade_id": "cell-5a2eb84298c32b21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Implementando el Generador\n",
    "\n",
    "En las GANs, el generador es el modelo que toma muestras de un espacio latente como entrada y genera datos que se asemejan a los datos del conjunto de entrenamiento. En este caso, es un modelo con una entrada bidimensional, que recibirá puntos aleatorios (z₁, z₂), y una salida bidimensional que debe proporcionar puntos (x̃₁, x̃₂) que se parezcan a los del conjunto de datos de entrenamiento.\n",
    "\n",
    "La implementación es similar a lo que se hizo para el discriminador. En primer lugar, se debe crear una clase Generador que herede de nn.Module, definiendo la arquitectura de la red neuronal, y luego se necesita instanciar un objeto Generador:\n",
    "\n",
    "El generador representa la red neuronal generadora. Está compuesto por dos capas ocultas con 16 y 32 neuronas, ambas con activación ReLU, y una capa de activación lineal con 2 neuronas en la salida. De esta manera, la salida consistirá en un vector con dos elementos que pueden ser cualquier valor que varíe desde menos infinito hasta infinito, lo que representará (x̃₁, x̃₂)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "619f21d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:23.897912Z",
     "start_time": "2023-08-22T01:05:23.883333Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a986c3b286afc722eb1496160cf8753",
     "grade": false,
     "grade_id": "cell-fbe58b897da39442",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "\n",
    "            nn.Linear(2, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb1376",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d3fe03132aeefcb81a12da4f5ff8c11",
     "grade": false,
     "grade_id": "cell-8291ccef4c3b322e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Entrenando el Modelo\n",
    "\n",
    "Primero se deben configurar algunos parámetros como siempre lo hemos hecho:\n",
    "\n",
    "* La tasa de aprendizaje (lr): Se utilizará para adaptar los pesos de la red.\n",
    "\n",
    "* Número de épocas (num_epochs): Define cuántas repeticiones de entrenamiento utilizando todo el conjunto de entrenamiento se llevarán a cabo.\n",
    "\n",
    "* loss_function a la función de pérdida de entropía cruzada binaria BCELoss(), que es la función de pérdida que se utilizará para entrenar los modelos.\n",
    "\n",
    "La función de pérdida de entropía cruzada binaria es adecuada para entrenar el discriminador porque considera una tarea de clasificación binaria. También es adecuada para entrenar el generador, ya que alimenta su salida al discriminador, que proporciona una salida binaria observable.\n",
    "\n",
    "PyTorch implementa varias reglas de actualización de pesos para el entrenamiento de modelos en torch.optim. Se utilizará el algoritmo Adam para entrenar los modelos del discriminador y del generador. Para crear los optimizadores utilizando torch.optim.\n",
    "\n",
    "Después, se debe implementar un ciclo de entrenamiento en el que las muestras de entrenamiento se alimenten a los modelos y se actualicen sus pesos para minimizar la función de pérdida:\n",
    "\n",
    "En las GAN, se actualizan los parámetros del discriminador y del generador en cada iteración de entrenamiento. Como generalmente se hace para todas las redes neuronales, el proceso de entrenamiento consiste en dos ciclos, uno para las épocas de entrenamiento y otro para los batch de cada época. Dentro del ciclo interno, se comienza a preparar los datos para entrenar el discriminador. Los pasos a seguir deben ser:\n",
    "\n",
    "* Se obtienen las muestras reales del batch actual del cargador de datos y se asignan a real_samples. Observen que la primera dimensión del tensor tiene el número de elementos igual a batch_size. Esta es la forma estándar de organizar los datos en PyTorch, donde cada línea del tensor representa una muestra del batch.\n",
    "\n",
    "* Se utiliza torch.ones() para crear etiquetas con el valor 1 para las muestras reales, y luego se asignan las etiquetas a real_samples_labels.\n",
    "\n",
    "* Se crean las muestras generadas almacenando datos aleatorios en latent_space_samples, que luego se alimentan al generador para obtener generated_samples.\n",
    "\n",
    "* Se utiliza torch.zeros() para asignar el valor 0 a las etiquetas para las muestras generadas, y luego se almacenan las etiquetas en generated_samples_labels.\n",
    "\n",
    "* Se concatenan las muestras reales y generadas y las etiquetas, y se almacenan en all_samples y all_samples_labels, que se utilizarán para entrenar el discriminador.\n",
    "\n",
    "Después se entrena el discriminador siguiendo estos pasos:\n",
    "\n",
    "* Es necesario borrar los gradientes en cada paso de entrenamiento para evitar acumularlos. Esto se hace utilizando .zero_grad().\n",
    "\n",
    "* Se calcula la salida del discriminador utilizando los datos de entrenamiento en all_samples.\n",
    "\n",
    "* Se calcula la función de pérdida utilizando la salida del modelo en output_discriminator y las etiquetas en all_samples_labels.\n",
    "\n",
    "* Se calculan los gradientes para actualizar los pesos con loss_discriminator.backward().\n",
    "\n",
    "* Se actualizan los pesos del discriminador llamando a optimizer_discriminator.step().\n",
    "\n",
    "A continuación, se preparan los datos para entrenar el generador. Se almacenan datos aleatorios en latent_space_samples, con un número de líneas igual a batch_size. Se utilizan dos columnas ya que se proporcionan datos bidimensionales como entrada al generador.\n",
    "\n",
    "Se entrena el generador de la siguiente manera:\n",
    "\n",
    "* Se borran los gradientes con .zero_grad().\n",
    "\n",
    "* Se alimenta el generador con latent_space_samples y se almacena su salida en generated_samples.\n",
    "\n",
    "* Se alimenta la salida del generador al discriminador y se almacena su salida en output_discriminator_generated, que se utilizará como la salida del modelo completo.\n",
    "\n",
    "* Se calcula la función de pérdida utilizando la salida del sistema de clasificación almacenada en output_discriminator_generated y las etiquetas en real_samples_labels, que son todas iguales a 1.\n",
    "\n",
    "* Se calculan los gradientes y se actualizan los pesos del generador. Recuerda que cuando entrenaste el generador, mantuviste los pesos del discriminador congelados ya que creaste optimizer_generator con su primer argumento igual a generator.parameters().\n",
    "\n",
    "* Se muestran los valores de las funciones de pérdida del discriminador y del generador al final de cada diez épocas.\n",
    "\n",
    "Dado que los modelos utilizados en este ejemplo tienen pocos parámetros, el entrenamiento se completará en pocos minutos. Más adelante, se utilizará la GAN entrenada para generar algunas muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4636dd8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:46.120167Z",
     "start_time": "2023-08-22T01:05:23.899960Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5815eeb4598e64dc1cdd03fe3e99507c",
     "grade": false,
     "grade_id": "cell-5185aa0971c6e2d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'e:\\\\Universidad\\\\2024\\\\Deep-Learning\\\\Lab6\\\\DEEP-LEARNING-LAB6-S10-2024\\\\imgs\\\\epoch_0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 75\u001b[0m\n\u001b[0;32m     73\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(epoch))\n\u001b[0;32m     74\u001b[0m name \u001b[38;5;241m=\u001b[39m path_imgs \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(epoch)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 75\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     77\u001b[0m list_images\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "File \u001b[1;32mc:\\Users\\inmar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1022\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[1;32m-> 1023\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1024\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\inmar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\figure.py:3378\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3374\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[0;32m   3375\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[0;32m   3376\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m-> 3378\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\inmar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mc:\\Users\\inmar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32mc:\\Users\\inmar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:526\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_jpg\u001b[1;34m(self, filename_or_obj, pil_kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_jpg\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;66;03m# savefig() has already applied savefig.facecolor; we now set it to\u001b[39;00m\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;66;03m# white to make imsave() blend semi-transparent figures against an\u001b[39;00m\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;66;03m# assumed white background.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m mpl\u001b[38;5;241m.\u001b[39mrc_context({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msavefig.facecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m\"\u001b[39m}):\n\u001b[1;32m--> 526\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\inmar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:458\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    457\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 458\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\inmar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\matplotlib\\image.py:1689\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1687\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1688\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[1;32m-> 1689\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\inmar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\PIL\\Image.py:2563\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2561\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2562\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2563\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2565\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'e:\\\\Universidad\\\\2024\\\\Deep-Learning\\\\Lab6\\\\DEEP-LEARNING-LAB6-S10-2024\\\\imgs\\\\epoch_0.jpg'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_images = []\n",
    "\n",
    "# Aprox 1 linea para que decidan donde guardar un set de imagen que vamos a generar de las graficas\n",
    "# path_imgs =\n",
    "# YOUR CODE HERE\n",
    "path_imgs = \"figs/\"\n",
    "random.seed(seed_)\n",
    "np.random.seed(seed_)\n",
    "torch.manual_seed(seed_)\n",
    "torch.cuda.manual_seed(seed_)\n",
    "\n",
    "lr = 0.001\n",
    "num_epochs = 100\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n, (real_samples, _) in enumerate(train_loader):\n",
    "        # Data for training the discriminator\n",
    "        real_samples_labels = torch.ones((batch_size, 1))\n",
    "        latent_space_samples = torch.randn((batch_size, 2))\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        generated_samples_labels = torch.zeros((batch_size, 1))\n",
    "        all_samples = torch.cat((real_samples, generated_samples))\n",
    "        all_samples_labels = torch.cat(\n",
    "            (real_samples_labels, generated_samples_labels)\n",
    "        )\n",
    "\n",
    "        # Training the discriminator\n",
    "        # Aprox 2 lineas para\n",
    "        # setear el discriminador en zero_grad\n",
    "        # output_discriminator =\n",
    "        # YOUR CODE HERE\n",
    "        discriminator.zero_grad()\n",
    "        output_discriminator = discriminator(all_samples)\n",
    "        loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n",
    "        # Aprox dos lineas para\n",
    "        # llamar al paso backward sobre el loss_discriminator\n",
    "        # llamar al optimizador sobre optimizer_discriminator\n",
    "        # YOUR CODE HERE\n",
    "        loss_discriminator.backward()\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "        # Data for training the generator\n",
    "        latent_space_samples = torch.randn((batch_size, 2))\n",
    "\n",
    "        # Training the generator\n",
    "        # Aprox 2 lineas para\n",
    "        # setear el generador en zero_grad\n",
    "        # output_discriminator =\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        generator.zero_grad()\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        output_discriminator_generated = discriminator(generated_samples)\n",
    "        loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n",
    "        \n",
    "        # Aprox dos lineas para\n",
    "        # llamar al paso backward sobre el loss_generator\n",
    "        # llamar al optimizador sobre optimizer_generator\n",
    "        # YOUR CODE HERE\n",
    "        loss_generator.backward()\n",
    "        optimizer_generator.step()\n",
    "        \n",
    "        # Guardamos las imagenes\n",
    "        if epoch % 2 == 0 and n ==  batch_size - 1:\n",
    "            generated_samples_detached = generated_samples.detach()\n",
    "            plt.plot(generated_samples_detached[:, 0], generated_samples_detached[:, 1], \".\")\n",
    "            plt.xlabel(\"X1\")\n",
    "            plt.ylabel(\"X2\")\n",
    "            plt.title(\"Epoch \"+str(epoch))\n",
    "            name = path_imgs + \"epoch_\"+str(epoch)+\".jpg\"\n",
    "            plt.savefig(name, format=\"jpg\")\n",
    "            plt.close()\n",
    "            list_images.append(name)\n",
    "\n",
    "        # Show loss\n",
    "        if epoch % 10 == 0 and n == batch_size - 1:\n",
    "            print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n",
    "            print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83693347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:14:15.207336Z",
     "start_time": "2023-08-22T01:14:15.189394Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1876d2a5898ac2733d001d55af81c83b",
     "grade": true,
     "grade_id": "cell-43271ed91b07bf15",
     "locked": true,
     "points": 70,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(35):        \n",
    "    assert compare_numbers(new_representation(loss_generator), \"3c3d\", '0x1.bd70a3d70a3d7p-1')\n",
    "    \n",
    "with tick.marks(35):        \n",
    "    assert compare_numbers(new_representation(loss_discriminator), \"3c3d\", '0x1.6666666666666p-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a6ef6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87d04696bcc63a71a682bd776f5ed905",
     "grade": false,
     "grade_id": "cell-3a3cdb9d5e36ea4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Revisión de lo Generado\n",
    "\n",
    "Las GAN están diseñadas para generar datos. Por lo tanto, una vez que se haya completado el proceso de entrenamiento, se pueden obtener algunas muestras aleatorias del espacio latente y alimentarlas al generador para obtener algunas muestras generadas.\n",
    "\n",
    "Luego se pueden trazar las muestras generadas y verificar si se asemejan a los datos de entrenamiento. Antes de trazar los datos de generated_samples, será necesario utilizar .detach() para obtener un tensor fuera del gráfico computacional de PyTorch, que luego se utilizará para calcular los gradientes:\n",
    "\n",
    "Se puede observar que la distribución de los datos generados se asemeja a la de los datos reales. Al utilizar un tensor de muestras de espacio latente fijo y alimentarlo al generador al final de cada época durante el proceso de entrenamiento, se puede visualizar la evolución del entrenamiento:\n",
    "\n",
    "Es importante señalar que al comienzo del proceso de entrenamiento, la distribución de los datos generados es muy diferente de la de los datos reales. Sin embargo, a medida que avanza el entrenamiento, el generador aprende la distribución de los datos reales.\n",
    "\n",
    "Ahora que se ha realizado la primera implementación de una red generativa adversaria, se pasará a una aplicación más práctica utilizando imágenes en la parte 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f8c042",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:46.151620Z",
     "start_time": "2023-08-22T01:05:46.136631Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5206dfbaaed23fedda75a98235a5a05a",
     "grade": false,
     "grade_id": "cell-9550386d10b7ff02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "latent_space_samples = torch.randn(100, 2)\n",
    "generated_samples = generator(latent_space_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ced56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:17:27.195854Z",
     "start_time": "2023-08-22T01:17:27.178827Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c049857dcd843ef11c3fffd112388c5",
     "grade": true,
     "grade_id": "cell-d5c4c4e3c6b03baa",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with tick.marks(15):        \n",
    "    assert compare_numbers(new_representation(generated_samples[len(generated_samples)-1][0]), \"3c3d\", '0x1.6000000000000p+2')\n",
    "    \n",
    "with tick.marks(15):        \n",
    "    assert compare_numbers(new_representation(generated_samples[len(generated_samples)-1][1]), \"3c3d\", '0x1.6000000000000p+2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58976a46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:46.386400Z",
     "start_time": "2023-08-22T01:05:46.168619Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "082d622cfd145fa4df612dfb3f435b72",
     "grade": false,
     "grade_id": "cell-6826fa4e5e1b1e94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "generated_samples = generated_samples.detach()\n",
    "plt.plot(generated_samples[:, 0], generated_samples[:, 1], \".\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.title(\"Final Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c2ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:47.811714Z",
     "start_time": "2023-08-22T01:05:46.387907Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93006e15e08c6a8fec71364ce4e90ec0",
     "grade": false,
     "grade_id": "cell-64f5584694f2c558",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualización del progreso de entrenamiento\n",
    "# Para que esto se ve bien, por favor reinicien el kernel y corran todo el notebook\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "images = [Image.open(path) for path in list_images]\n",
    "\n",
    "# Save the images as an animated GIF\n",
    "gif_path = \"animation.gif\"  # Specify the path for the GIF file\n",
    "images[0].save(gif_path, save_all=True, append_images=images[1:], loop=0, duration=300)\n",
    "display(IPImage(filename=gif_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f51a18",
   "metadata": {},
   "source": [
    "*Las respuestas de estas preguntas representan el 10% de este notebook*\n",
    "\n",
    "**PREGUNTAS:**\n",
    "* Describa en una frase la diferencia entre los modelos discriminativos y los generativos\n",
    "* Explique como el concepto de MinMax se aplica a los GAN\n",
    "* Describa lo que se está observando en la imagen GIF que se generó\n",
    "* ¿Cree que se ha creado un buen modelo? ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6553d0e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T01:05:47.827200Z",
     "start_time": "2023-08-22T01:05:47.813706Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a278e529c2dc267965b339a9df5b702",
     "grade": true,
     "grade_id": "cell-9dc291ab56b45d7a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print()\n",
    "print(\"La fraccion de abajo muestra su rendimiento basado en las partes visibles de este laboratorio\")\n",
    "tick.summarise_marks() # "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
